### [ 머신러닝 ]

#### [ 지도학습 ]

##### [ SVM ]

- 분류/회귀 분석에 사용되는 강력한 지도학습 모델
- 분류를 위해 **결정 경계(결정 초평면)** 을 찾아 분류
    
&nbsp;    → 초평면은 두 클래스 사이의 **최대 마진**을 보장하는 방식으로 선택

![](https://velog.velcdn.com/images/yejingksdpwls/post/48dea1ac-27a6-43bc-b250-926b98d47924/image.png)


( *마진* : 두 클래스 간의 가장 가까운 데이터 포인트 간의 거리 )

- *목적*
    - 마진을 최대화하면서 결정 초평면을 찾아 데이터 포인트를 정확히 분류하는 것
- 코드

```python
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 모델 생성 및 학습
model = SVC(kernel='linear')
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")
```
&nbsp;
##### [ KNN ]

- 분류/회귀 분석에 사용되는 비모수적 방법
- 새로운 데이터 포인트를 기존 데이터 포인트 중 **가장 가까운 K개의 이웃**과 비교하여 분류

![](https://velog.velcdn.com/images/yejingksdpwls/post/7b3c1338-dee2-4a64-a2b6-847089f21a25/image.png)


→ 거리 측정 : 일반적으로 “*유클리드 거리 “* 사용됨

- 코드

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 모델 생성 및 학습
model = KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")
```
&nbsp
##### [ 나이브 베이즈 ]

- **베이즈 정리**를 기반으로 하는 통계적 분류 기법
- ***베이즈 정리***
![](https://velog.velcdn.com/images/yejingksdpwls/post/27292a41-1658-45fd-be78-baeabe3b2e86/image.png)

    - P(A|B) : B 주어졌을 때의 A 확률 (사후 확률)
    - P(B|A) : A 주어졌을 때의 B 확률
    - P(A), P(B) : A, B의 사전 확률
    
- **‘나이브’** ⇒ 각 틍징이 **독립적**이라고 가정하기 때문
- *종류*
    - 가우시안 나이브베이즈 ( 정규 분포 )
    - 베르누이 나이브베이즈 ( 이항 분포 )
    - 멀티노미얼 나이브베이즈 ( 다항 분포 )
- 코드

```python
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 가우시안 나이브 베이즈 모델 생성 및 학습
model = GaussianNB()
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")
```
&nbsp
##### [ 의사결정나무 ]

- 데이터 특징을 기준으로 의사결정 규칙을 만들어 분류/회귀하는 **예측** 모델
- **분류기준**
    - 정보이득
    
![](https://velog.velcdn.com/images/yejingksdpwls/post/82dbad61-362c-4b64-8be5-7a3f7aa69e95/image.png)

→ 엔트로피 지수 : 불확실성
- 지니계수
![](https://velog.velcdn.com/images/yejingksdpwls/post/c785410e-c018-403d-a8c6-5b902420a057/image.png)


- 코드

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 의사결정나무 모델 생성 및 학습
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")
```