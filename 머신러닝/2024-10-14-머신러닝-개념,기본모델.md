### [ 머신러닝 ]

- **정의**

컴퓨터가 명시적으로 프로그래밍 되지 않아도 데이터를 통해 “규칙과 논리”를 찾아 학습/예측하는 모델

&nbsp;

- **종류**
    - *지도 학습* : 목표 변수 존재
    - *비지도 학습* : 목표 변수 존재하지 않음
    - 강화학습 :  특정 행위를 하는 인공지능
    - 앙상블 학습 : 여러 머신러닝 모델 결합

&nbsp;

- **핵심 구성요소**
    - 데이터 셋
    - 특징 (피처)
    - 레이블 (목표 변수)
    - 모델
    - 학습

&nbsp;

- **학습 과정**
![](https://velog.velcdn.com/images/yejingksdpwls/post/ab0cabe0-8e9d-4e50-9156-a765ad3a0da8/image.png)
&nbsp;

### [ 모델 ]

1. **회귀모델 (예측 모델)**
    - #### 선형회귀
        - 종속 변수와 하나 이상의 독립 변수 간의 “선형 관계’를 모델링
            - *단순선형* : 독립 변수 1개
            - 다중선형 : 독립 변수 2개 이상
        
        &nbsp;
        
        - 오차를 최소화 하는 절편/계수 추정 (ex. B0, B1) = “학습”
        - 오차 최소화 방법 : ex ) 경사하강법
        
        &nbsp;
        
        - #### ***단순선형회귀***
            - ***기본 수식***
            ![](https://velog.velcdn.com/images/yejingksdpwls/post/e813e8b9-cd94-4764-ac3f-ff23f411b95e/image.png)
            &nbsp
            
        
        - ***코드***

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 데이터 생성
X = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5],[6,6]])
y = np.array([1, 2, 3, 4, 5, 6])

# 데이터 분할 (훈련 데이터와 테스트 데이터)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 선형 회귀 모델 생성 및 학습
model = LinearRegression()
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 모델 평가
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
```

&nbsp;

- #### ***다중선형회귀***
    - 독립 변수 간의 비선형 관계를 모델링 (비선형 데이터에 유리)
    
    &nbsp;
    
    - **기본수식**
    ![](https://velog.velcdn.com/images/yejingksdpwls/post/8d3568c0-c183-49f7-93f2-707586ee036e/image.png)  
    &nbsp;
    
    - **코드**

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 데이터 생성
X = np.array([[1], [2], [3], [4], [5], [6]])
y = np.array([1, 4, 9, 16, 25, 36])

# 다항 특징 생성 (차수 2)
poly = PolynomialFeatures(degree=2) # 독립 변수의 제곱 변수 만듦
X_poly = poly.fit_transform(X)

# 데이터 분할 (훈련 데이터와 테스트 데이터)
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)

# 다항 회귀 모델 생성 및 학습
model = LinearRegression()
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 모델 평가
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
```
&nbsp;

1. #### **로지스틱 회귀** (분류 모델)
- 종속 변수 이진 변수 일 때 사용
- 결과값 0,1 사이에 위치하게 하는 “시그모이드 함수“ 사용
&nbsp;


- **시그모이드 함수**
![](https://velog.velcdn.com/images/yejingksdpwls/post/f662bb5e-32c6-4f19-bf27-0e5d4c4f43d0/image.png)

—> 입력값 0과 1 사이의 값응로 변환
&nbsp;
&nbsp;

- **비용 함수 : 로그 손실 함수 : 엔트로피 손실 함수**
![](https://velog.velcdn.com/images/yejingksdpwls/post/f6eac4e9-23c4-4b85-9e1d-6f841a3dcd0f/image.png)

- ***코드***

```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 모델 생성 및 학습
model = LogisticRegression()
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
print(f"Confusion Matrix:\n{confusion_matrix(y_test, y_pred)}")
```