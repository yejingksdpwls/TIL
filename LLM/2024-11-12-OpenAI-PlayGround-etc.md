### [ 오늘 공부한 내용 ]
OpenAI Playground, 프롬프트 엔지니어링, 다양한 텍스트 처리 기법 및 임베딩 기법에 대해 학습했습니다. 이를 통해 모델의 설정과 최적화 방법을 이해하고, 프롬프트 작성 기술을 개선할 수 있는 방법을 배웠습니다.


&nbsp;
## [ OpenAI Playground ]

- 정의
    - 웹 기반 실험 환경
    - 프롬프트 입력해보고, 그에 대한 응답 실시간으로 확인 가능

- 할 수 있는 것
    1. **텍스트 생성** : 사용자 입력 프롬프트를 바탕으로 GPT 모델이 답변 생성
    2. **다양한 작업 테스트** : 요약, 번역, 질문 답변, 창의적 글쓰기 등
    3. **프롬프트 엔지니어링 실험**

- 주요 설정 파라미터
    - 모델 설택 : GPT-4 family, GPT-3.5 family
    - 온도 (temperature) : 랜덤성 조정
    - 토큰 길이
    - 탑-피 (Top-p) : 응답의 다양성 제어
        - 1.0 : 모든 가능한 답변 고려해 다양한 응답 생성
        - 0.5 : 확률 상위 50%에 해당하는 답변들만 선택해 더 집중된 응답 생성
    - 프롬프트 형식

- *주의할 점*
    - Frequency Penalty : 이미 사용한 표현 반복하지 않도록 하는 설정 (높이면 중복된 표현 줄이게 됨)
    - Presence Penalty : 새로운 표현 더 많이 사용하도록 유도하는 설정 (높이면 더 다양한 표현)\

- 역할
    - User : 대화 주체, 프롬프트 입력하는 사용자
    - Assistant : 요청에 응답하는 역할
    - System : 대화의 전반적인 규칙, 지침 제공하는 역할

&nbsp;
## [ 프롬프트 엔지니어링 ]

- 정의
    - 인공지능 모델에 적절한 **입력(프롬프트)**를 작성해 모델이 최적의 응답을 하도록 유도하는 기술
    - 프롬프트의 **구조**나 **어조**를 조정해, 답변의 품질과 일관성을 높이는 것이 중요

- 동작 원리
    - **패턴 인식**과 **확률 계산**에 기반해 학습
    - 어떤 단어가 어떤 맥락에서 자주 등장하는지 학습해, 주어진 프롬프트에 맞는 답변을 확률젹으로 생성
    - 모델의 **패턴 학습 메커니즘**을 활용해 모델이 적절한 경로로 답을 유도하도록 하는 방법

- 기본 원칙
    - 명확한 요청 사항 전달하기
    - 정보 제공 필수
    - 제약 조건 제공
    - 복잡한 작업 분할
    
&nbsp;
### [ Shot 계열의 프롬프팅 기법 ]

- Zero-Shot
    - 아무 예제를 주지 않고 *지침*만 전달하는 방식
    - 구체적인 요구 이끌어내기 어려움
    - 준비 과정이 필요없고 사전 지식이 없는 내용에 대해 질문할 때 사용
- One-Shot
    - 예제를 하나 전달해주는 방식
- Few-Shot
    - 유도하는 능력이 더욱 향상됨
    - 입력, 출력 외에 **과정**도 함께 제공하면 추론 능력 더욱 향상됨

&nbsp;
### [ Act As 류의 프롬프팅 기법 : 페르소나 기법 ]

- 페르소나
    - LLM에게 성격, 관점, 역할을 부여하는 것
    - 페르소나 **창조**도 가능 (가상의 인물이나 직업 등)

- Act As
    - 역할 부여 프롬프트
    - 모델에게 특정한 직업, 역할을 부여해 그 직업이나 성격에 맞는 답변을 얻을 수 있음

&nbsp;
### [ CoT 기법 ]

- 논리적 추론의 한계
    - LLM은 문맥을 기반으로 확률적 답변을 제공하기 때문에, 수학 문제나 논리적 퍼즐 같은 문제에 정확도 낮음

- 정의
    - 단계별로 추론 과정을 설명하도록 모델에게 유도하는 기법
    - 중간 추론 단계를 명시하면 복잡한 문제를 더 정확히 풀 수 있게 함

&nbsp;
## [ 주요 텍스트 처리 기법 ]

- 토큰화
- 정규화
- 불용어 제거
- 형태소 분석
- 어간 추출, 표제어 추출
- 문장 분리 및 길이 조정

&nbsp;
### [ 임베딩 기법 ]

- 정의 : 텍스트 데이터를 **벡터(숫자배열)**로 변환하는 과정
- Bag of Words
    - 단어의 빈도만을 기반으로 텍스트를 벡터화
    - 단어의 순서나 문맥 고려하지 않음
- TF-IDF
    - 단순한 단어 빈도 욍도 단어 중요도를 반영한 기법
    - 특정 문서 내에서 자주 등장하지만 전체 문서에서 드물게 등장할 시 해 당문서에서 중요한 단어로 간주
- Word2Vec, Glove
    - 단어 간의 의미적 유사성을 반영하는 기법
    - 단어 고차원 벡터로 변환
    - Word2Vec : 주위 단어들에 기반해 단어 의미 학습
    - Glove : 전체 문맥을 기반으로 단어 간의 공통 패턴 학습
- Transformer 기반 임베딩 ( BERT, GPT )
    - 문장의 문맥을 고려해 더 깊이 있는 의미 반영
    - BERT : 양방향으로 문맥 고려
    - GPT : 자동 완성 및 생성에 강점을 둔 기법
  
&nbsp;
## [ 배운점 ]
* 프롬프트 엔지니어링을 통해 AI 모델이 더 정확하고 일관된 답변을 생성할 수 있도록 유도할 수 있다는 점이 중요하다는 것을 배웠습니다.

* Shot 기법과 Act As 기법을 활용하여 모델의 답변 스타일을 조정하고, CoT 기법으로 복잡한 문제 해결 능력을 개선할 수 있음을 알게 되었습니다.

* 임베딩 기법을 통해 텍스트 데이터를 벡터로 변환하여 의미를 반영하고, 다양한 기법을 통해 벡터화된 정보를 어떻게 활용할 수 있을지에 대해 배웠습니다.