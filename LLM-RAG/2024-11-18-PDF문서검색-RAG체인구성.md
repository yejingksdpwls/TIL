### [ 오늘 공부한 내용 ]
* OpenAI API 키 설정과 모델 초기화 방법

* LangChain을 활용한 PDF 문서 로드 및 텍스트 분할 방식

* FAISS 벡터 스토어 구축과 검색 기능 구현

* RAG 체인(Debug 포함) 설계 및 사용자 입력에 따른 질의응답 처리



1.**API 키 설정 및 모델 초기화**
* os.environ을 사용하여 OpenAI API 키를 환경 변수에 저장
* ChatOpenAI를 사용해 GPT-4 모델 초기화 후 기본 질의응답 테스트 수행
```python
import os
from getpass import getpass
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

# API 키 설정
os.environ['OPENAI_API_KEY'] = getpass('OpenAI API key 입력: ')

# 모델 초기화
model = ChatOpenAI(model="gpt-4o-mini")
response = model.invoke([HumanMessage(content='안녕하세요, 무엇을 도와드릴까요?')])
print(response.content)
```

2.**PDF 문서 로드**
* PyPDFLoader를 통해 PDF 파일의 페이지를 개별 문서로 로드
```python
from langchain.document_loaders import PyPDFLoader

# PDF 파일 로드
loader = PyPDFLoader("AI.pdf")

# 페이지 별 문서 로드
docs = loader.load()
print(docs[:2])  # 첫 두 페이지 내용 확인
```

3.**텍스트 분할**
* CharacterTextSplitter와 RecursiveCharacterTextSplitter를 사용하여 텍스트를 문서 조각으로 나누고, 분할 기준과 중복 범위를 설정
```python
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter

# CharacterTextSplitter 사용
text_splitter = CharacterTextSplitter(
    separator="\n\n",
    chunk_size=100,
    chunk_overlap=10,
    length_function=len,
    is_separator_regex=False
)
splits = text_splitter.split_documents(docs)
print(splits[:5])

# RecursiveCharacterTextSplitter 사용
recursive_text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=100,
    chunk_overlap=10,
    length_function=len,
    is_separator_regex=False
)
splits = recursive_text_splitter.split_documents(docs)
print(splits[:5])
```

4.**임베딩 및 벡터 스토어 구축**
* OpenAI의 "text-embedding-ada-002" 모델을 사용해 텍스트 임베딩 생성
* FAISS를 활용해 벡터 스토어 생성, 고유 ID를 기반으로 페이지를 매핑
```python
from langchain_openai import OpenAIEmbeddings
import faiss
from langchain_community.vectorstores import FAISS
from uuid import uuid4

# OpenAI 임베딩 모델 초기화
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")

# 페이지 별 고유 ID 생성
uuids = [f"page_{i+1}" for i in range(len(splits))]

# FAISS 벡터 스토어 생성
vector_store = FAISS.from_documents(documents=splits, ids=uuids, embedding=embeddings)
```

5.**문서 검색기 설정**
* 벡터 스토어를 기반으로 문서 검색기를 생성하여 유사도를 기준으로 문서를 검색하도록 설정
```python
retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 1})
```

6.**RAG 체인 구성**
* 검색된 문서를 프롬프트에 포함시켜 질의응답을 수행하는 RAG 체인을 설계
* 디버깅 목적의 DebugPassThrough 클래스와 텍스트 변환을 위한 ContextToText 클래스를 구현
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# 프롬프트 템플릿 정의
contextual_prompt = ChatPromptTemplate.from_messages([
    ("system", "Answer the question using only the following context."),
    ("user", "Context: {context}\\n\\nQuestion: {question}")
])

# 디버깅 클래스
class DebugPassThrough(RunnablePassthrough):
    def invoke(self, *args, **kwargs):
        output = super().invoke(*args, **kwargs)
        print("Debug Output:", output)
        return output

# 문서를 텍스트로 변환
class ContextToText(RunnablePassthrough):
    def invoke(self, inputs, config=None, **kwargs):
        context_text = "\n".join(
            [doc.page_content for doc in inputs["context"]])
        return {"context": context_text, "question": inputs["question"]}

# RAG 체인 구성
rag_chain_debug = {
    "context": retriever,
    "question": DebugPassThrough()
} | DebugPassThrough() | ContextToText() | contextual_prompt | model
```

7.**사용자 입력에 따른 질의응답**
* 사용자 질문을 입력받아 RAG 체인을 실행하고, 최종 응답을 출력하는 루프 설계
```python
query = ''
while query != 'stop': 
    print("========================")
    query = input("질문을 입력하세요: ")
    response = rag_chain_debug.invoke(query)
    print("Final Response:")
    print(response.content)
```

### [ 어려움이 있었던 부분 ]
* 단일 문서의 처리
	페이지를 분할한 후 고유 ID를 설정하는 방식에서 단일 문서에 적합한 설정법 고민
	* docstore 및 index_to_docstore_id 매개변수의 필요성 검토

* Debugging 및 RAG 체인 설계
	* DebugPassThrough와 같은 디버깅 도구를 활용해 체인의 중간 결과를 확인하는 방법 학습

* FAISS와 LangChain의 연동
	* 벡터 스토어에 문서를 추가하고, 유사도 검색이 제대로 작동하는지 확인하는 과정에서 설정 오류 발생
    
    
### [ 배운 점 ]
* 텍스트 분할 및 문서 검색은 정보 검색 시스템의 핵심임을 깨달음

* FAISS와 LangChain의 연계를 통해 효율적인 검색 및 응답 체인을 설계할 수 있음

* 디버깅 도구를 활용해 체인의 각 단계의 중간 결과를 확인하며 문제를 해결하는 방법을 익힘

* OpenAI의 임베딩과 FAISS를 함께 사용해 작은 문서부터 대규모 문서까지 검색 시스템을 확장할 가능성을 알게 됨