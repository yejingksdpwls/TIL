### [ 오늘 공부한 내용 ]
오늘은 Transformers 라이브러리를 사용해 IMDb 데이터셋을 BERT로 파인튜닝하여 영화 리뷰를 긍정 또는 부정으로 분류하는 모델을 구현하는 과정을 공부했습니다. 
&nbsp;
&nbsp;
## [ AI 활용 ]

### [ BERT의 사전 학습 ]

- **MLM**
    - 일부 단어를 마스킹 한 후, 이를 예측하도록 모델 학습
    - 문맥을 양방향으로 이해할 수 있음
- **NSP**
    - 두 문장이 주어졌을 때, 두 번째 문장이 첫 번째 문장 뒤에 자연스럽게 이어지는지 예측
    - 문장 간의 관계 이해하는 능력 학습

&nbsp;
### [ 파인튜닝 ]

- 정의
    - 사전 학습된 모델을 특정 작업에 맞게 추가로 학습시키는 과정
- 특징
    - 작업 특화 (특정 작업에 맞춰 최적화)
    - 사전 학습 가중치 활용
    - 적은 데이터로도 가능함

&nbsp;
### [ 파인튜닝 실습 코드 ]
&nbsp;
1. **라이브러리 및 데이터셋 로드**

```python
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from datasets import load_dataset
import torch
```
- `transformers`: BERT 모델과 토크나이저, 그리고 학습을 위한 Trainer API를 제공합니다.
- `datasets`: IMDb 데이터셋을 쉽게 로드하기 위한 라이브러리입니다.
- `torch`: PyTorch 기반으로 모델을 학습합니다.

&nbsp;
2. **데이터셋 로드 및 샘플링**

```python
dataset = load_dataset("imdb")
train_dataset = dataset['train'].shuffle(seed=42).select(range(1000))  # 1000개 샘플로 축소
test_dataset = dataset['test'].shuffle(seed=42).select(range(500))  # 500개 샘플로 축소
```
* IMDb 데이터셋을 로드한 후, 훈련과 테스트 데이터로 분리하고, 학습 속도를 높이기 위해 각각 1000개와 500개의 샘플로 축소했습니다.

&nbsp;
3. **토크나이저 초기화 및 토크나이징 함수 정의**

```python
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True)
```
- BertTokenizer를 사용해 텍스트 데이터를 BERT 입력 형식으로 변환하며, padding="max_length"와 truncation=True를 통해 고정 길이 입력을 보장합니다.

&nbsp;
4. **데이터셋 토크나이징 및 포맷 설정**

```python
train_dataset = train_dataset.map(tokenize_function, batched=True)
test_dataset = test_dataset.map(tokenize_function, batched=True)

train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
```
- `map()` : tokenize_function을 각 데이터에 적용한 후, set_format으로 PyTorch 텐서로 변환해 모델에 전달할 수 있도록 준비합니다.

&nbsp;
5. **BERT 모델과 학습 인자 설정**
```python
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    evaluation_strategy="epoch",
    save_steps=10_000,
    save_total_limit=2,
)
```
* `BertForSequenceClassification`을 로드하고, 분류 레이블을 2개(긍정, 부정)로 설정합니다.
* `TrainingArguments`에서 학습 파라미터를 지정합니다.

&nbsp;
6. **Trainer 객체 초기화 및 학습 수행**

```python
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)

trainer.train()
trainer.evaluate()
```
- Trainer API로 학습을 간단하게 수행할 수 있습니다. train() 함수로 모델을 학습하고 evaluate()로 평가를 수행합니다.

&nbsp;
7. **평가 지표 함수 추가 및 정확도 확인**
```python
import numpy as np
from sklearn.metrics import accuracy_score

def compute_metrics(p):
    preds = np.argmax(p.predictions, axis=1)
    labels = p.label_ids
    acc = accuracy_score(labels, preds)
    return {'accuracy': acc}

trainer.compute_metrics = compute_metrics
eval_result = trainer.evaluate()
print(f"Accuracy: {eval_result['eval_accuracy']:.4f}")
```
- compute_metrics 함수를 정의하여 정확도를 계산한 뒤, Trainer 객체에 추가해 평가할 때마다 정확도를 확인할 수 있도록 설정했습니다.

#### [ 코드 결과 ]
![](https://velog.velcdn.com/images/yejingksdpwls/post/5dc4ff7d-cef2-4ec8-ac34-58677313f680/image.png)

&nbsp;

### [ 배운 점 ]
* **API 권한 확인의 중요성**: API 키에 따라 사용 가능한 모델이 달라질 수 있으므로, 접근 권한이 없을 경우 OpenAI 지원팀에 문의하는 것이 필요함.
- **패키지 최신 상태 유지**: 패키지를 최신 버전으로 유지하면 API와의 호환성을 높일 수 있음.