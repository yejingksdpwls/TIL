오늘은 생성형 AI의 원리, 텍스트 및 이미지 생성 모델 코딩, 그리고 FastAPI를 활용한 웹 애플리케이션 구축에 대해 학습했습니다.

## [ 생성형 AI ]

### [ 생성형 AI 직접 만들기의 한계 ]

- 대규모 데이터와 컴퓨팅 자원 필요
    - 데이터 수집 어려움
    - 컴퓨팅 자원의 한계
- 모델 구조 복잡성
    - 모델 아키텍처 설계 어려움
    - 하이퍼 파라미터 튜닝 어려움
- 훈련 과정의 불안정성
    - 모델 붕괴 현상 가능성
    - 균형 잡힌 학습

&nbsp;

### [ 생성형 모델 기본 원리 ]

1. **랜덤성**
    1. 역할
        
        : 모델이 출력 데이터 생성할 때, 일정한 확률에 따라 다양한 선택지 고려하게 함
        
    2. 확률 분포
        
        : 학습 데이터를 통해 어은 확률 분포를 기반으로 새로운 데이터 생성
        
2. **조건성**
    1. 입력된 조건에 따라 결과를 다르게 생성
    2. 중요성
        
        : 조건성 덕분에 매우 다양한 상황에 적응할 수 있음
        
&nbsp;
**[ 텍스트 기반 생성형 모델 원리 ]**

- **입력 토큰화**
- **확률 예측**
- **랜덤 선택**
- **반복 생성**

**[ 이미지 기반 생성형 모델 원리 ]**

- **텍스트 인코딩**
- **이미지 생성**
- **세부 사항 추가**

**[ 오디오 기반 생성형 모델 원리 ]**

- **텍스트 또는 멜로디 인코딩**
- **오디오 생성**
- **랜덤성 적용**

&nbsp;
## [ GPT-4o 모델로 텍스트 생성 코드 ]

0. 사전 단계 : API 키 관리

```python
# chatgpt api 키 외부 env 파일로 저장 후 연결
from google.colab import files
files.upload()  # 파일 선택 창이 나타나면 .env 파일을 선택하여 업로드

from dotenv import load_dotenv
import os

load_dotenv()  # .env 파일 로드
api_key = os.getenv("OPENAI_API_KEY")  # 환경 변수 가져오기
```

&nbsp;
1. API 키 설정

```python
OpenAI.api_key = api_key
```

→ 키 `OpenAI.api_key`에 설정합니다. 이 키는 OpenAI API에 접근하는 인증 정보로 사용됩니다.

&nbsp;
2. 대화 생성

```python
completion = client.chat.completions.create(
    model = "gpt-4o",
    messages = [
        {'role': 'system', 'content': '너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게 해줘'},
        {'role': 'user', 'content': '안녕?'}
    ]
)
```

→ `client.chat.completions.create()`를 통해 대화를 생성합니다.

→ `model = "gpt-4o"`는 사용할 모델을 `gpt-4o`로 지정하며, 이 모델이 채팅에서 답변을 생성하게 됩니다.

→ `messages`는 챗봇이 대화를 진행하기 위해 참조하는 메시지 목록입니다.

→  첫 번째 메시지 `{'role': 'system', 'content': '너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게 해줘'}`는 챗봇의 역할을 지정했습니다.

→  두 번째 메시지 `{'role': 'user', 'content': '안녕?'}`는 사용자가 챗봇에게 인사를 건넨 부분입니다.

&nbsp;
3. 결과 출력

```python
print('Assistant: ' + completion.choices[0].message.content)
```

→ `completion.choices[0].message.content`는 생성된 대화 응답에서 첫 번째 응답의 내용을 추출합니다.

&nbsp;
## [ 이미지 생성 코드 실습 ]

1. Stable Diffusion 파이프라인 로드

```python
from diffusers import StableDiffusionPipeline
import torch

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", torch_dtype=torch.float16)
```

→ `StableDiffusionPipeline.from_pretrained()`를 통해 Stable Diffusion 모델(`stable-diffusion-v1-4`)을 로드합니다.

→ `torch_dtype=torch.float16`은 메모리 사용량을 줄이기 위해 `float16` 형식으로 모델을 로드하는 설정입니다.

1. GPU 설정

```python
pipe = pipe.to("cuda")
```

→  모델을 GPU(`cuda`)로 전송하여 연산 속도를 높입니다. 이를 통해 이미지를 생성할 때 CPU보다 빠르게 연산할 수 있습니다.

3. 이미지 생성,저장 및 출력

```python
prompt = "A futuristic cityscape with flying cars at sunset"
image = pipe(prompt).images[0]

image.save("generated_image.png")
image.show()
```

→ `prompt`는 모델이 이미지를 생성할 때 참고할 텍스트 설명입니다.

→ `pipe(prompt)`는 이 프롬프트를 기반으로 이미지를 생성하며, `.images[0]`로 생성된 이미지 중 첫 번째 이미지를 선택합니다.

→ `image.save()`는 생성된 이미지를 `generated_image.png`로 저장합니다.

→ `image.show()`는 생성된 이미지를 화면에 출력하는 함수입니다.

1. 모델 세부 조정

```python
image = pipe(prompt, guidance_scale=7.5, num_inference_steps=50).images[0]
```

→  `guidance_scale`: 텍스트 프롬프트의 영향을 얼마나 강하게 반영할지 결정합니다. 값이 높을수록 프롬프트의 내용이 강하게 반영된 이미지를 생성하지만, 너무 높으면 품질이 떨어질 수 있습니다.

→ `num_inference_steps`: 이미지 생성 과정에서의 추론 단계를 지정하며, 단계 수가 많을수록 이미지의 품질이 향상되지만, 생성 시간이 더 오래 걸립니다.

 
&nbsp;
## [ API 심화 ]

### [ 모델 서빙 ]

- 정의
    - 학습된 머신러닝 모델을 실제 애플리케이션에서 사용할 수 있도록 제공하는 과정
- 주요 개념
    - **RESTful API**
        - REST 아키텍처 스타일
        - HTTP를 통해 클라이언트와 서버 간에 데이터 주고받는 방식
        - ‘경로’를 통해 리소스에 접근
        - 개요
            - GET : 서버에서 데이터 가져올 때 사용
            - POST : 서버에 데이터 보낼 때 사용
            - PUT : 서버의 데이터 업데이트할 때 사용
            - DELETE : 서버의 데이터 삭제할 때 사용
            
    
    - **FastAPI**
        - python 으로 작성된 빠르고 간단한 웹 프레이워크
        - RESTful API 구축하는데 매우 적합

&nbsp;
### [ FastAPI 라이브러리를 이용한 간단 웹 애플리케이션 구축 ]

1. 인스턴스 생성

```python
from fastapi import FastAPI

app = FastAPI()
```

→  `app`이라는 이름으로 `FastAPI` 클래스의 인스턴스를 생성합니다. 이 인스턴스는 웹 애플리케이션의 주요 설정과 경로 정보를 관리합니다.

2. 경로 정의 및 응답 생성

```python
@app.get('/')
def read_root():
  return{'message': 'Hello World!'}
```

→ `@app.get('/')` 데코레이터는 애플리케이션에 기본 경로(`/`)에 대한 GET 요청이 들어왔을 때 실행할 함수 `read_root`를 정의합니다.
→ `read_root` 함수는 단순히 `{"message": "Hello World!"}`라는 JSON 형태의 응답을 반환합니다. 사용자가 `http://127.0.0.1:8000/` 주소에 GET 요청을 보내면 이 응답이 브라우저나 API 클라이언트에 표시됩니다.

### [ 배운 점 ]

* 생성형 AI는 텍스트, 이미지, 오디오 등 각기 다른 데이터 유형에 맞는 원리를 바탕으로 설계된다는 점에서 흥미로웠습니다.

* 텍스트 생성과 이미지 생성의 API 호출 방식이 유사했으며, 모델 서빙을 통해 실생활 애플리케이션에 모델을 적용하는 가능성을 느낄 수 있었습니다.

* FastAPI를 사용하여 간단하지만 유용한 웹 애플리케이션을 빠르게 구축할 수 있는 방법을 배웠습니다.