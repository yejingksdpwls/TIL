### [ 타이타닉 생존 예측 : 분류 모델 ]
* **데이터 불러오기**
```python
import seaborn as sns
titanic = sns.load_dataset('titanic')
```
&nbsp; --> 'seaborn' 패키지에 내장되어 있는 'titanic' 데이터 셋 로드
&nbsp;
&nbsp;
* **결측치 확인 및 보정**
```python
titanic.isnull().sum()

titanic['age']=titanic['age'].fillna(titanic['age'].median())
titanic['embarked']=titanic['embarked'].fillna(titanic['embarked'].mode()[0])
titanic['age'].isnull().sum()
titanic['embarked']
```
&nbsp; --> `titanic.isnull().sum()` : 각 열 별 결측치의 개수 확인
&nbsp; --> `titanic['age']=titanic['age'].fillna(titanic['age'].median())` : 'age' 열의 결측치는 중앙값으로 보정
&nbsp; --> `titanic['embarked']=titanic['embarked'].fillna(titanic['embarked'].mode()[0])` : 'embarked' 열의 결측치는 최빈값으로 보정
&nbsp;
&nbsp;
* **범주형 변수 인코딩**
( 모델이 좀 더 확실하게 학습할 수 있도록 )
```python
titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})
titanic['alive'] = titanic['alive'].map({'no': 1, 'yes': 0})
titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2,})
```
&nbsp; --> `titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})` : 'male'은 0, 'female'은 1로 인코딩
&nbsp; --> `titanic['alive'] = titanic['alive'].map({'no': 1, 'yes': 0})` : 'no'는 1, 'yes'는 0으로 인코딩
&nbsp; --> `titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2,})` : 'C'는 0으로, 'Q'는 1로, 'S'는 2로 인코딩
&nbsp;
&nbsp;
* **데이터 분할 및 표준화**
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = titanic.iloc[:, list(range(1,8))+[-1]]
y = titanic.iloc[:,0]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_scaler = StandardScaler()
X_train =  X_scaler.fit_transform(X_train)
X_test = X_scaler.transform(X_test)
```
&nbsp; --> `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)` : 학습 데이터는 80%, 테스트 데이터는 20%로 분할
&nbsp; --> 
```python
X_scaler = StandardScaler()
X_train =  X_scaler.fit_transform(X_train)
X_test = X_scaler.transform(X_test)
```
: 일반적으로 분류 모델에서 독립 변수만 표준화하고 종속 변수는 표준화하지 않음
&nbsp;
&nbsp;
* **로지스틱 회귀 모델**
```python
from sklearn.linear_model import LogisticClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

model = LogisticClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
```
&nbsp;
&nbsp;
* **랜덤포레스트 모델**
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

model = RandomForestClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
```
&nbsp;
&nbsp;
* **XGBoost 모델**
```python
import xgboost as xgb
from sklearn.metrics import mean_squared_error

model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
```
&nbsp; --> `XGBRegressor` : 예측 모델일 경우 (종속 변수가 연속형)
&nbsp; --> `XGBClassifier` : 분류 모델일 경우 (종속 변수가 2개 이상의 범주형)